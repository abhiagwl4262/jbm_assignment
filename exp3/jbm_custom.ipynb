{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from os import makedirs\n",
    "from os.path import expanduser, exists, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "img_width, img_height = 256, 256\n",
    "num_classes = 2\n",
    "n_epoches = 100\n",
    "input_shape = (img_height, img_width, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dir = \"../data/train\"\n",
    "valid_data_dir = \"../data/valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 204 images belonging to 2 classes.\n",
      "Found 46 images belonging to 2 classes.\n",
      "('train data: ', 204)\n",
      "('valid data: ', 46)\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                                samplewise_center=True,  # set each sample mean to 0\n",
    "                                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                                samplewise_std_normalization=True,  # divide each input by its std\n",
    "#                                 zca_whitening=False,  # apply ZCA whitening\n",
    "#                                 rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                                width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                                height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "                                horizontal_flip=True,  # randomly flip images\n",
    "                                vertical_flip=True) # randomly flip images                                \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(img_height, img_width),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    seed=10)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "valid_generator = val_datagen.flow_from_directory(valid_data_dir,\n",
    "                                                target_size=(img_height, img_width),\n",
    "                                                batch_size=batch_size,\n",
    "                                                seed=10)\n",
    "\n",
    "print (\"train data: \", train_generator.n)\n",
    "print (\"valid data: \", valid_generator.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    # create model  \n",
    "    model = Sequential()\n",
    "    BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),activation='relu', input_shape=input_shape, padding = 'same'))\n",
    "    model.add(BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3),activation='relu', padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(num_classes, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    \n",
    "    model.add(Dense(num_class, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_78 (Conv2D)           (None, 256, 256, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 256, 256, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 30, 30, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 30, 30, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 15, 15, 2)         9218      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 7, 7, 2)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_10  (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 1,581,768\n",
      "Trainable params: 1,579,784\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = create_baseline()\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model.save_weights(\"jbm_custom_weights_15.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 71s 6s/step - loss: 0.8598 - acc: 0.4723 - val_loss: 0.9241 - val_acc: 0.4375\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 66s 5s/step - loss: 0.6933 - acc: 0.4932 - val_loss: 0.9617 - val_acc: 0.4375\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.6969 - acc: 0.4880 - val_loss: 0.6913 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.6925 - acc: 0.5277 - val_loss: 0.6928 - val_acc: 0.5625\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 62s 5s/step - loss: 0.6925 - acc: 0.5729 - val_loss: 0.6928 - val_acc: 0.5625\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 59s 5s/step - loss: 0.6909 - acc: 0.5523 - val_loss: 0.6927 - val_acc: 0.5625\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.6860 - acc: 0.5229 - val_loss: 0.6926 - val_acc: 0.5625\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 62s 5s/step - loss: 0.6692 - acc: 0.5312 - val_loss: 0.6927 - val_acc: 0.5312\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.6847 - acc: 0.5867 - val_loss: 0.7325 - val_acc: 0.4375\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.6805 - acc: 0.5967 - val_loss: 0.6931 - val_acc: 0.3750\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 59s 5s/step - loss: 0.6836 - acc: 0.5900 - val_loss: 0.6923 - val_acc: 0.5625\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 62s 5s/step - loss: 0.6631 - acc: 0.5833 - val_loss: 0.6922 - val_acc: 0.5625\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.6918 - acc: 0.5971 - val_loss: 0.6921 - val_acc: 0.5625\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.6976 - acc: 0.5746 - val_loss: 0.6921 - val_acc: 0.5625\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 80s 7s/step - loss: 0.6626 - acc: 0.5851 - val_loss: 0.6920 - val_acc: 0.5625\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 62s 5s/step - loss: 0.6666 - acc: 0.5938 - val_loss: 0.6919 - val_acc: 0.5625\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 59s 5s/step - loss: 0.6491 - acc: 0.7303 - val_loss: 0.6918 - val_acc: 0.5625\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.6724 - acc: 0.6513 - val_loss: 0.6917 - val_acc: 0.5625\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 62s 5s/step - loss: 0.6573 - acc: 0.6406 - val_loss: 0.6916 - val_acc: 0.5625\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 59s 5s/step - loss: 0.6593 - acc: 0.6173 - val_loss: 0.6915 - val_acc: 0.5625\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.6272 - acc: 0.6637 - val_loss: 0.6914 - val_acc: 0.5625\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 62s 5s/step - loss: 0.6257 - acc: 0.6562 - val_loss: 0.6913 - val_acc: 0.5625\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 59s 5s/step - loss: 0.6397 - acc: 0.6198 - val_loss: 0.6912 - val_acc: 0.5625\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 62s 5s/step - loss: 0.6609 - acc: 0.6667 - val_loss: 0.6911 - val_acc: 0.5625\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.6350 - acc: 0.6790 - val_loss: 0.6910 - val_acc: 0.5625\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.6218 - acc: 0.6717 - val_loss: 0.6909 - val_acc: 0.5625\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 62s 5s/step - loss: 0.6130 - acc: 0.7031 - val_loss: 0.6908 - val_acc: 0.5625\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 66s 5s/step - loss: 0.6262 - acc: 0.7014 - val_loss: 0.6906 - val_acc: 0.5625\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.6494 - acc: 0.6372 - val_loss: 0.6906 - val_acc: 0.5625\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 62s 5s/step - loss: 0.5929 - acc: 0.6354 - val_loss: 0.6904 - val_acc: 0.5625\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 62s 5s/step - loss: 0.5779 - acc: 0.6752 - val_loss: 0.6903 - val_acc: 0.5625\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.6057 - acc: 0.7219 - val_loss: 0.6902 - val_acc: 0.5625\n",
      "Epoch 33/100\n",
      " 8/12 [===================>..........] - ETA: 15s - loss: 0.5753 - acc: 0.7031"
     ]
    }
   ],
   "source": [
    "base_model.fit_generator(train_generator,\n",
    "                      steps_per_epoch = train_generator.n // batch_size,\n",
    "                      validation_data = valid_generator,\n",
    "                      validation_steps = valid_generator.n // batch_size,\n",
    "                      epochs = n_epoches,\n",
    "                      verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save_weights(\"jbm_inception_weights_5.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
